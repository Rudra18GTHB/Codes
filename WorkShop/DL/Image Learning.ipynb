{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d7b79c-7f8a-4235-be8b-82be151860d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 23:51:26.593940: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-24 23:51:26.628990: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-24 23:51:26.629092: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-24 23:51:26.630096: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-24 23:51:26.636017: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-24 23:51:26.636714: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-24 23:51:30.636510: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-04-24 23:51:35.468740: I itex/core/wrapper/itex_cpu_wrapper.cc:60] Intel Extension for Tensorflow* AVX512 CPU backend is loaded.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential,activations,losses,metrics,layers,optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16882cc3-4904-4105-850f-4f9d4d0efd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model architecture\n",
    "model=Sequential()\n",
    "model.add(layers.Conv2D(64,(3,3),input_shape=(224,224,3),activation='relu'))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Conv2D(16,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Conv2D(8,(3,3),activation='relu'))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(32,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid')) #binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b7027c0-6491-46ce-806a-17f6d220bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "addbfeb3-1014-44ee-bee4-40d42587d236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 111, 111, 64)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 32)        18464     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 16)        4624      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 12, 12, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 10, 10, 8)         1160      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 5, 5, 8)           0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                12864     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77945 (304.47 KB)\n",
      "Trainable params: 77945 (304.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4254a65f-eed9-41cd-9f70-03010fb4d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b6a0e39-ab0f-4ed9-af6c-db920a3913fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path=\"images/train\"\n",
    "validation_path=\"images/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf95e0ff-8c56-41a9-a837-bd207e8dde73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140 images belonging to 2 classes.\n",
      "Found 60 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen=ImageDataGenerator(rescale=1./255)\n",
    "validation_data_gen=ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data=train_data_gen.flow_from_directory(train_path,target_size=(224,224),class_mode=\"binary\")\n",
    "validation_data=train_data_gen.flow_from_directory(validation_path,target_size=(224,224),class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6866b39-b7a7-46c2-bd40-c18ddb995c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 3s 644ms/step - loss: 1.7336e-05 - accuracy: 1.0000 - val_loss: 1.7331e-06 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 3s 699ms/step - loss: 3.1482e-05 - accuracy: 1.0000 - val_loss: 1.5015e-06 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 3s 604ms/step - loss: 2.1118e-05 - accuracy: 1.0000 - val_loss: 8.3274e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 3s 642ms/step - loss: 1.2950e-05 - accuracy: 1.0000 - val_loss: 3.4128e-07 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 3s 648ms/step - loss: 3.7904e-06 - accuracy: 1.0000 - val_loss: 1.7930e-07 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 3s 626ms/step - loss: 2.1783e-06 - accuracy: 1.0000 - val_loss: 1.0867e-07 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 3s 606ms/step - loss: 1.3428e-06 - accuracy: 1.0000 - val_loss: 7.5211e-08 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 3s 710ms/step - loss: 1.1429e-06 - accuracy: 1.0000 - val_loss: 5.3967e-08 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 4s 711ms/step - loss: 7.5815e-07 - accuracy: 1.0000 - val_loss: 4.3192e-08 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 3s 610ms/step - loss: 6.2719e-07 - accuracy: 1.0000 - val_loss: 3.6813e-08 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f57b02ed370>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data,epochs=10,validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2de22654-a5b2-4b7d-adc8-7fcb5ad73cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b0983e9-d3df-4d5f-bbd7-b60360f0ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_image(image_path):\n",
    "    img = image.load_img(image_path, target_size = (224,224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = img_array/255\n",
    "    img_array = np.expand_dims(img_array, axis =0)\n",
    "    return img_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4ad5a52-b5ca-4058-a256-ac424a67181d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_image_path = \"Test Images/WIN_20240425_12_26_08_Pro.jpg\"\n",
    "img_array = preprocessing_image(new_image_path)\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e4a9087-6915-4fe4-b2b2-909c0878965e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "RightHand\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(img_array)\n",
    "if prediction[0] >= 0.5:\n",
    "    print(\"LeftHand\")\n",
    "else:\n",
    "    print(\"RightHand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cbea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 =  Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19069839",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[0:-3]:\n",
    "    model1.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28534533",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"CNN myData.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow (IntelÂ® oneAPI 2024.1)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-tf-2024.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
